{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_functions as da\n",
    "import ml_functions as ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from simpleloop\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "from datetime import timedelta\n",
    "import random\n",
    "from scipy import optimize\n",
    "import time\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\n",
    "from sklearn import preprocessing, cross_validation, svm, metrics, tree, decomposition, svm\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier, OrthogonalMatchingPursuit, RandomizedLogisticRegression\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See ml_functions.py for additional helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magicloop code adapted from Rayid Ghani: https://github.com/rayidghani/magicloops/blob/master/magicloops.py\n",
    "def LR():\n",
    "    return LogisticRegression(penalty = 'l1', C = 1e5)\n",
    "\n",
    "def KNN():\n",
    "    return KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "def DT():\n",
    "    return DecisionTreeClassifier()\n",
    "\n",
    "def SVM():\n",
    "    return svm.SVC(kernel = 'linear', probability = True, random_state = 3)\n",
    "\n",
    "def RF():\n",
    "    return RandomForestClassifier(n_estimators = 50, n_jobs = -1)\n",
    "\n",
    "def AB():\n",
    "    return AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                                                    algorithm=\"SAMME\",\n",
    "                                                    n_estimators=200)\n",
    "def GB():\n",
    "    return GradientBoostingClassifier(learning_rate = 0.05,\n",
    "                                    \tsubsample = 0.5,\n",
    "                                    \tmax_depth = 6,\n",
    "                                    \tn_estimators = 10)\n",
    "def NB():\n",
    "    return GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = models_to_run=['RF','DT','KNN', 'ET', 'AB', 'GB', 'LR', 'NB']\n",
    "\n",
    "def classifier_loop(df, features, start, grid_size='test', models_to_run = all_models):\n",
    "    \n",
    "    # define grid to use: test, small, large\n",
    "    clfs, grid = define_clfs_params(grid_size)\n",
    "    \n",
    "    X_test, X_train, y_test, y_train = train_test_over_time(df, features, start=start)\n",
    "    # call clf_loop and store results in results_df\n",
    "    results_df = ml.my_loop(models_to_run, clfs,grid, X_test, X_train, y_test, y_train)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_clfs_params(grid_size):\n",
    "    \"\"\"Define defaults for different classifiers.\n",
    "    Define three types of grids:\n",
    "    Test: for testing your code\n",
    "    Small: small grid\n",
    "    Large: Larger grid that has a lot more parameter sweeps\n",
    "    \"\"\"\n",
    "\n",
    "    clfs = {'RF': RandomForestClassifier(n_estimators=50, n_jobs=-1),\n",
    "        'ET': ExtraTreesClassifier(n_estimators=10, n_jobs=-1, criterion='entropy'),\n",
    "        'AB': AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=200),\n",
    "        'LR': LogisticRegression(penalty='l1', C=1e5),\n",
    "        'SVM': svm.SVC(kernel='linear', probability=True, random_state=0),\n",
    "        'GB': GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=10),\n",
    "        'NB': GaussianNB(),\n",
    "        'DT': DecisionTreeClassifier(),\n",
    "        'SGD': SGDClassifier(loss=\"hinge\", penalty=\"l2\"),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=3) \n",
    "            }\n",
    "\n",
    "    large_grid = { \n",
    "    'RF':{'n_estimators': [1,10,100,1000,10000], 'max_depth': [1,5,10,20,50,100], 'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10], 'n_jobs': [-1]},\n",
    "    'LR': { 'penalty': ['l1','l2'], 'C': [0.00001,0.0001,0.001,0.01,0.1,1,10]},\n",
    "    'SGD': { 'loss': ['hinge','log','perceptron'], 'penalty': ['l2','l1','elasticnet']},\n",
    "    'ET': { 'n_estimators': [1,10,100,1000,10000], 'criterion' : ['gini', 'entropy'] ,'max_depth': [1,5,10,20,50,100], 'max_features': ['sqrt','log2'],'min_samples_split': [2,5,10], 'n_jobs': [-1]},\n",
    "    'AB': { 'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1,10,100,1000,10000]},\n",
    "    'GB': {'n_estimators': [1,10,100,1000,10000], 'learning_rate' : [0.001,0.01,0.05,0.1,0.5],'subsample' : [0.1,0.5,1.0], 'max_depth': [1,3,5,10,20,50,100]},\n",
    "    'NB' : {},\n",
    "    'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],'min_samples_split': [2,5,10]},\n",
    "    'SVM' :{'C' :[0.00001,0.0001,0.001,0.01,0.1,1,10],'kernel':['linear']},\n",
    "    'KNN' :{'n_neighbors': [1,5,10,25,50,100],'weights': ['uniform','distance'],'algorithm': ['auto','ball_tree','kd_tree']}\n",
    "           }\n",
    "    \n",
    "    small_grid = { \n",
    "    'RF':{'n_estimators': [10,100], 'max_depth': [5,50], 'max_features': ['sqrt','log2'],'min_samples_split': [2,10], 'n_jobs': [-1]},\n",
    "    'LR': { 'penalty': ['l1','l2'], 'C': [0.00001,0.001,0.1,1,10]},\n",
    "    'SGD': { 'loss': ['hinge','log','perceptron'], 'penalty': ['l2','l1','elasticnet']},\n",
    "    'ET': { 'n_estimators': [10,100], 'criterion' : ['gini', 'entropy'] ,'max_depth': [5,50], 'max_features': ['sqrt','log2'],'min_samples_split': [2,10], 'n_jobs': [-1]},\n",
    "    'AB': { 'algorithm': ['SAMME', 'SAMME.R'], 'n_estimators': [1,10,100,1000,10000]},\n",
    "    'GB': {'n_estimators': [10,100], 'learning_rate' : [0.001,0.1,0.5],'subsample' : [0.1,0.5,1.0], 'max_depth': [5,50]},\n",
    "    'NB' : {},\n",
    "    'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,5,10,20,50,100],'min_samples_split': [2,5,10]},\n",
    "    'SVM' :{'C' :[0.00001,0.0001,0.001,0.01,0.1,1,10],'kernel':['linear']},\n",
    "    'KNN' :{'n_neighbors': [1,5,10,25,50,100],'weights': ['uniform','distance'],'algorithm': ['auto','ball_tree','kd_tree']}\n",
    "           }\n",
    "    \n",
    "    test_grid = { \n",
    "    'RF':{'n_estimators': [1], 'max_depth': [1], 'max_features': ['sqrt'],'min_samples_split': [10]},\n",
    "    'LR': { 'penalty': ['l1'], 'C': [0.01]},\n",
    "    'SGD': { 'loss': ['perceptron'], 'penalty': ['l2']},\n",
    "    'ET': { 'n_estimators': [1], 'criterion' : ['gini'] ,'max_depth': [1], 'max_features': ['sqrt'],'min_samples_split': [10]},\n",
    "    'AB': { 'algorithm': ['SAMME'], 'n_estimators': [1]},\n",
    "    'GB': {'n_estimators': [1], 'learning_rate' : [0.1],'subsample' : [0.5], 'max_depth': [1]},\n",
    "    'NB' : {},\n",
    "    'DT': {'criterion': ['gini'], 'max_depth': [1],'min_samples_split': [10]},\n",
    "    'SVM' :{'C' :[0.01],'kernel':['linear']},\n",
    "    'KNN' :{'n_neighbors': [5],'weights': ['uniform'],'algorithm': ['auto']}\n",
    "           }\n",
    "    \n",
    "    if (grid_size == 'large'):\n",
    "        return clfs, large_grid\n",
    "    elif (grid_size == 'small'):\n",
    "        return clfs, small_grid\n",
    "    elif (grid_size == 'test'):\n",
    "        return clfs, test_grid\n",
    "    else:\n",
    "        return 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_over_time(df, features, target='fully_funded', start='Jan 2011'):\n",
    "    dates = {}\n",
    "    dates['2011-01-01'] = ['2011-12-31', '2012-06-31']\n",
    "    dates['2011-07-01'] = ['2012-07-31', '2012-12-31']\n",
    "    dates['2012-01-01'] = ['2012-12-31', '2013-06-31']\n",
    "\n",
    "    if start == 'Jan 2011':\n",
    "        start = '2011-01-01'\n",
    "        end_train = dates[start][0]\n",
    "        end_test = dates[start][1]\n",
    "    elif start == 'Jul 2011':\n",
    "        start = '2011-07-01'\n",
    "        end_train = dates[start][0]\n",
    "        end_test = dates[start][1]\n",
    "    elif start == 'Jan 2012':\n",
    "        start = '2012-01-01'\n",
    "        end_train = dates[start][0]\n",
    "        end_test = dates[start][1]\n",
    "    \n",
    "        \n",
    "    x_test = da.specify_range(df, 'date_posted', start, end_train)\n",
    "    x_train = da.specify_range(df, 'date_posted', end_train, end_test)\n",
    "    x_test, x_train = x_test[features], x_train[features]\n",
    "\n",
    "    y_test = da.specify_range(df[['date_posted', target]], 'date_posted', start, end_train)\n",
    "    y_train = da.specify_range(df[['date_posted', target]], 'date_posted', end_train, end_test)\n",
    "    y_test, y_train = y_test[target], y_train[target]\n",
    "                         \n",
    "    return x_test, x_train, y_test, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load\n",
    "all_projects = da.read_data('projects.csv')\n",
    "outcomes = da.read_data('outcomes.csv')\n",
    "\n",
    "projects = da.specify_range(all_projects, 'date_posted', '2011-01-01', '2013-12-31')\n",
    "combined = pd.merge(projects, outcomes, on='projectid')\n",
    "funded = combined.loc[combined.fully_funded=='t']\n",
    "unfunded = combined.loc[combined.fully_funded=='f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.replace_na(combined, 'students_reached')\n",
    "inf = ['total_price_excluding_optional_support', 'total_price_including_optional_support', 'students_reached']\n",
    "for i in inf:\n",
    "    combined = da.remove_outliers(combined, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['projectid', 'teacher_acctid', 'schoolid', 'school_ncesid',\n",
       "       'school_latitude', 'school_longitude', 'school_city', 'school_state',\n",
       "       'school_zip', 'school_metro', 'school_district', 'school_county',\n",
       "       'school_charter', 'school_magnet', 'school_year_round', 'school_nlns',\n",
       "       'school_kipp', 'school_charter_ready_promise', 'teacher_prefix',\n",
       "       'teacher_teach_for_america', 'teacher_ny_teaching_fellow',\n",
       "       'primary_focus_subject', 'primary_focus_area',\n",
       "       'secondary_focus_subject', 'secondary_focus_area', 'resource_type',\n",
       "       'poverty_level', 'grade_level', 'fulfillment_labor_materials',\n",
       "       'total_price_excluding_optional_support',\n",
       "       'total_price_including_optional_support', 'students_reached',\n",
       "       'eligible_double_your_impact_match', 'eligible_almost_home_match',\n",
       "       'date_posted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = combined[['projectid', 'teacher_acctid', 'schoolid', 'school_ncesid',\n",
    "       'school_latitude', 'school_longitude', 'school_city', 'school_state',\n",
    "       'school_zip', 'school_metro', 'school_district', 'school_county',\n",
    "       'school_charter', 'school_magnet', 'school_year_round', 'school_nlns',\n",
    "       'school_kipp', 'school_charter_ready_promise', 'teacher_prefix',\n",
    "       'teacher_teach_for_america', 'teacher_ny_teaching_fellow',\n",
    "       'primary_focus_subject', 'primary_focus_area',\n",
    "       'secondary_focus_subject', 'secondary_focus_area', 'resource_type',\n",
    "       'poverty_level', 'grade_level', 'fulfillment_labor_materials',\n",
    "       'total_price_excluding_optional_support',\n",
    "       'total_price_including_optional_support', 'students_reached',\n",
    "       'eligible_double_your_impact_match', 'eligible_almost_home_match',\n",
    "       'date_posted','fully_funded']]\n",
    "# projects + fully funded \n",
    "\n",
    "y = combined[['date_posted', 'fully_funded']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ml.find_binary_cols(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natasha/MachineLearning2018/Homework3/ml_functions.py:442: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  for col in b:\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#b.remove('eligible_double_your_impact_match')\n",
    "ml.turn_to_1_0(classify, b)    \n",
    "classify['eligible_double_your_impact_match'] = classify['eligible_double_your_impact_match'].apply(lambda x: 1 if x=='t' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = [x for x in classify.columns if x not in b]   \n",
    "cats = ['school_metro', 'teacher_prefix', 'primary_focus_area', 'resource_type', 'poverty_level', 'grade_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = ml.category_cols(classify, cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.fulfillment_labor_materials.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['projectid', 'teacher_acctid', 'schoolid', 'school_ncesid',\n",
       "       'school_latitude', 'school_longitude', 'school_city', 'school_state',\n",
       "       'school_zip', 'school_district', 'school_county', 'school_charter',\n",
       "       'school_magnet', 'school_year_round', 'school_nlns', 'school_kipp',\n",
       "       'school_charter_ready_promise', 'teacher_teach_for_america',\n",
       "       'teacher_ny_teaching_fellow', 'primary_focus_subject',\n",
       "       'secondary_focus_subject', 'secondary_focus_area',\n",
       "       'fulfillment_labor_materials', 'total_price_excluding_optional_support',\n",
       "       'total_price_including_optional_support', 'students_reached',\n",
       "       'eligible_double_your_impact_match', 'eligible_almost_home_match',\n",
       "       'date_posted', 'fully_funded', 'rural', 'suburban', 'urban', 'Dr.',\n",
       "       'Mr.', 'Mrs.', 'Ms.', 'Applied Learning', 'Health & Sports',\n",
       "       'History & Civics', 'Literacy & Language', 'Math & Science',\n",
       "       'Music & The Arts', 'Special Needs', 'Books', 'Other', 'Supplies',\n",
       "       'Technology', 'Trips', 'Visitors', 'high poverty', 'highest poverty',\n",
       "       'low poverty', 'moderate poverty', 'Grades 3-5', 'Grades 6-8',\n",
       "       'Grades 9-12', 'Grades PreK-2', 'disc_students_reached',\n",
       "       'disc_price_excluding', 'disc_price_including'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.add_discrete_variable(classify, 'students_reached', 'disc_students_reached', 5)\n",
    "ml.add_discrete_variable(classify, 'total_price_excluding_optional_support', 'disc_price_excluding', 10)\n",
    "ml.add_discrete_variable(classify, 'total_price_including_optional_support', 'disc_price_including', 10)\n",
    "classify.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ 'school_charter',\n",
    "       'school_magnet', 'school_year_round', 'school_nlns', 'school_kipp',\n",
    "       'school_charter_ready_promise', 'teacher_teach_for_america',\n",
    "       'teacher_ny_teaching_fellow', \n",
    "       'fulfillment_labor_materials', 'total_price_excluding_optional_support',\n",
    "       'total_price_including_optional_support', 'students_reached',\n",
    "       'eligible_double_your_impact_match', 'eligible_almost_home_match',\n",
    "         'rural', 'suburban', 'urban', 'Dr.',\n",
    "       'Mr.', 'Mrs.', 'Ms.', 'Applied Learning', 'Health & Sports',\n",
    "       'History & Civics', 'Literacy & Language', 'Math & Science',\n",
    "       'Music & The Arts', 'Special Needs', 'Books', 'Other', 'Supplies',\n",
    "       'Technology', 'Trips', 'Visitors', 'high poverty', 'highest poverty',\n",
    "       'low poverty', 'moderate poverty', 'Grades 3-5', 'Grades 6-8',\n",
    "       'Grades 9-12', 'Grades PreK-2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates Used\n",
    "\n",
    "#### dates[start] = [end_train, end_test]\n",
    "#### dates['2011-01-01'] = ['2011-12-31', '2012-06-31'] - Jan 2011\n",
    "#### dates['2011-07-01'] = ['2012-07-31', '2012-12-31'] - Jul 2011\n",
    "#### dates['2012-01-01'] = ['2012-12-31', '2013-06-31'] - Jan 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "DT\n",
      "KNN\n",
      "ET\n",
      "AB\n",
      "GB\n",
      "LR\n",
      "NB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>clf</th>\n",
       "      <th>parameters</th>\n",
       "      <th>auc-roc</th>\n",
       "      <th>baseline</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>r_at_2</th>\n",
       "      <th>r_at_5</th>\n",
       "      <th>r_at_10</th>\n",
       "      <th>r_at_20</th>\n",
       "      <th>r_at_30</th>\n",
       "      <th>r_at_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.509881</td>\n",
       "      <td>0.692669</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.603811</td>\n",
       "      <td>0.833066</td>\n",
       "      <td>0.916550</td>\n",
       "      <td>0.958279</td>\n",
       "      <td>0.972185</td>\n",
       "      <td>0.983311</td>\n",
       "      <td>0.014421</td>\n",
       "      <td>0.017433</td>\n",
       "      <td>0.060116</td>\n",
       "      <td>0.132308</td>\n",
       "      <td>0.276692</td>\n",
       "      <td>0.421047</td>\n",
       "      <td>0.709785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.588031</td>\n",
       "      <td>0.692669</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905115</td>\n",
       "      <td>0.631331</td>\n",
       "      <td>0.754212</td>\n",
       "      <td>0.852529</td>\n",
       "      <td>0.014421</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>0.072163</td>\n",
       "      <td>0.130658</td>\n",
       "      <td>0.182289</td>\n",
       "      <td>0.326644</td>\n",
       "      <td>0.615382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 5, 'weigh...</td>\n",
       "      <td>0.562579</td>\n",
       "      <td>0.692669</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.536810</td>\n",
       "      <td>0.752683</td>\n",
       "      <td>0.767585</td>\n",
       "      <td>0.768324</td>\n",
       "      <td>0.014421</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>0.072163</td>\n",
       "      <td>0.077491</td>\n",
       "      <td>0.217328</td>\n",
       "      <td>0.332436</td>\n",
       "      <td>0.554600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>0.524557</td>\n",
       "      <td>0.692669</td>\n",
       "      <td>0.997992</td>\n",
       "      <td>0.998997</td>\n",
       "      <td>0.999599</td>\n",
       "      <td>0.999799</td>\n",
       "      <td>0.667235</td>\n",
       "      <td>0.667358</td>\n",
       "      <td>0.800377</td>\n",
       "      <td>0.014392</td>\n",
       "      <td>0.028842</td>\n",
       "      <td>0.072134</td>\n",
       "      <td>0.144326</td>\n",
       "      <td>0.192656</td>\n",
       "      <td>0.289028</td>\n",
       "      <td>0.577737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 1}</td>\n",
       "      <td>0.588031</td>\n",
       "      <td>0.692669</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905115</td>\n",
       "      <td>0.631331</td>\n",
       "      <td>0.754212</td>\n",
       "      <td>0.852529</td>\n",
       "      <td>0.014421</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>0.072163</td>\n",
       "      <td>0.130658</td>\n",
       "      <td>0.182289</td>\n",
       "      <td>0.326644</td>\n",
       "      <td>0.615382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>0.588031</td>\n",
       "      <td>0.692669</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905115</td>\n",
       "      <td>0.631331</td>\n",
       "      <td>0.754212</td>\n",
       "      <td>0.852529</td>\n",
       "      <td>0.014421</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>0.072163</td>\n",
       "      <td>0.130658</td>\n",
       "      <td>0.182289</td>\n",
       "      <td>0.326644</td>\n",
       "      <td>0.615382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight=None, ...</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>0.645114</td>\n",
       "      <td>0.692669</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.819458</td>\n",
       "      <td>0.829454</td>\n",
       "      <td>0.854764</td>\n",
       "      <td>0.846054</td>\n",
       "      <td>0.826758</td>\n",
       "      <td>0.782766</td>\n",
       "      <td>0.012046</td>\n",
       "      <td>0.023659</td>\n",
       "      <td>0.059856</td>\n",
       "      <td>0.123389</td>\n",
       "      <td>0.244288</td>\n",
       "      <td>0.358063</td>\n",
       "      <td>0.565025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.612108</td>\n",
       "      <td>0.692669</td>\n",
       "      <td>0.841365</td>\n",
       "      <td>0.820461</td>\n",
       "      <td>0.808587</td>\n",
       "      <td>0.821264</td>\n",
       "      <td>0.788587</td>\n",
       "      <td>0.778350</td>\n",
       "      <td>0.763229</td>\n",
       "      <td>0.012133</td>\n",
       "      <td>0.023687</td>\n",
       "      <td>0.058350</td>\n",
       "      <td>0.118553</td>\n",
       "      <td>0.227695</td>\n",
       "      <td>0.337098</td>\n",
       "      <td>0.550922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type                                                clf  \\\n",
       "0         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "1         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "2        KNN  KNeighborsClassifier(algorithm='auto', leaf_si...   \n",
       "3         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "4         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "5         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "6         LR  LogisticRegression(C=0.01, class_weight=None, ...   \n",
       "7         NB                            GaussianNB(priors=None)   \n",
       "\n",
       "                                          parameters   auc-roc  baseline  \\\n",
       "0  {'max_depth': 1, 'max_features': 'sqrt', 'min_...  0.509881  0.692669   \n",
       "1  {'criterion': 'gini', 'max_depth': 1, 'min_sam...  0.588031  0.692669   \n",
       "2  {'algorithm': 'auto', 'n_neighbors': 5, 'weigh...  0.562579  0.692669   \n",
       "3  {'criterion': 'gini', 'max_depth': 1, 'max_fea...  0.524557  0.692669   \n",
       "4          {'algorithm': 'SAMME', 'n_estimators': 1}  0.588031  0.692669   \n",
       "5  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti...  0.588031  0.692669   \n",
       "6                       {'C': 0.01, 'penalty': 'l1'}  0.645114  0.692669   \n",
       "7                                                 {}  0.612108  0.692669   \n",
       "\n",
       "     p_at_1    p_at_2    p_at_5   p_at_10   p_at_20   p_at_30   p_at_50  \\\n",
       "0  1.000000  0.603811  0.833066  0.916550  0.958279  0.972185  0.983311   \n",
       "1  1.000000  1.000000  1.000000  0.905115  0.631331  0.754212  0.852529   \n",
       "2  1.000000  1.000000  1.000000  0.536810  0.752683  0.767585  0.768324   \n",
       "3  0.997992  0.998997  0.999599  0.999799  0.667235  0.667358  0.800377   \n",
       "4  1.000000  1.000000  1.000000  0.905115  0.631331  0.754212  0.852529   \n",
       "5  1.000000  1.000000  1.000000  0.905115  0.631331  0.754212  0.852529   \n",
       "6  0.835341  0.819458  0.829454  0.854764  0.846054  0.826758  0.782766   \n",
       "7  0.841365  0.820461  0.808587  0.821264  0.788587  0.778350  0.763229   \n",
       "\n",
       "     r_at_1    r_at_2    r_at_5   r_at_10   r_at_20   r_at_30   r_at_50  \n",
       "0  0.014421  0.017433  0.060116  0.132308  0.276692  0.421047  0.709785  \n",
       "1  0.014421  0.028871  0.072163  0.130658  0.182289  0.326644  0.615382  \n",
       "2  0.014421  0.028871  0.072163  0.077491  0.217328  0.332436  0.554600  \n",
       "3  0.014392  0.028842  0.072134  0.144326  0.192656  0.289028  0.577737  \n",
       "4  0.014421  0.028871  0.072163  0.130658  0.182289  0.326644  0.615382  \n",
       "5  0.014421  0.028871  0.072163  0.130658  0.182289  0.326644  0.615382  \n",
       "6  0.012046  0.023659  0.059856  0.123389  0.244288  0.358063  0.565025  \n",
       "7  0.012133  0.023687  0.058350  0.118553  0.227695  0.337098  0.550922  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_loop(classify, features, 'Jan 2011')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "DT\n",
      "KNN\n",
      "ET\n",
      "AB\n",
      "GB\n",
      "LR\n",
      "NB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>clf</th>\n",
       "      <th>parameters</th>\n",
       "      <th>auc-roc</th>\n",
       "      <th>baseline</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>r_at_2</th>\n",
       "      <th>r_at_5</th>\n",
       "      <th>r_at_10</th>\n",
       "      <th>r_at_20</th>\n",
       "      <th>r_at_30</th>\n",
       "      <th>r_at_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.501993</td>\n",
       "      <td>0.746965</td>\n",
       "      <td>0.925550</td>\n",
       "      <td>0.962775</td>\n",
       "      <td>0.985120</td>\n",
       "      <td>0.992560</td>\n",
       "      <td>0.996280</td>\n",
       "      <td>0.997520</td>\n",
       "      <td>0.998478</td>\n",
       "      <td>0.012381</td>\n",
       "      <td>0.025758</td>\n",
       "      <td>0.065935</td>\n",
       "      <td>0.132866</td>\n",
       "      <td>0.266750</td>\n",
       "      <td>0.400611</td>\n",
       "      <td>0.668357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.602844</td>\n",
       "      <td>0.746965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852215</td>\n",
       "      <td>0.763294</td>\n",
       "      <td>0.842191</td>\n",
       "      <td>0.905285</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>0.026754</td>\n",
       "      <td>0.066931</td>\n",
       "      <td>0.114079</td>\n",
       "      <td>0.204368</td>\n",
       "      <td>0.338230</td>\n",
       "      <td>0.605976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 5, 'weigh...</td>\n",
       "      <td>0.580896</td>\n",
       "      <td>0.746965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669598</td>\n",
       "      <td>0.816806</td>\n",
       "      <td>0.823311</td>\n",
       "      <td>0.843404</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>0.026754</td>\n",
       "      <td>0.066931</td>\n",
       "      <td>0.089633</td>\n",
       "      <td>0.218696</td>\n",
       "      <td>0.330647</td>\n",
       "      <td>0.564554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>0.508140</td>\n",
       "      <td>0.746965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>0.026754</td>\n",
       "      <td>0.066931</td>\n",
       "      <td>0.133861</td>\n",
       "      <td>0.267746</td>\n",
       "      <td>0.401607</td>\n",
       "      <td>0.669375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 1}</td>\n",
       "      <td>0.602844</td>\n",
       "      <td>0.746965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852215</td>\n",
       "      <td>0.763294</td>\n",
       "      <td>0.842191</td>\n",
       "      <td>0.905285</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>0.026754</td>\n",
       "      <td>0.066931</td>\n",
       "      <td>0.114079</td>\n",
       "      <td>0.204368</td>\n",
       "      <td>0.338230</td>\n",
       "      <td>0.605976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>0.602959</td>\n",
       "      <td>0.746965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.853061</td>\n",
       "      <td>0.763125</td>\n",
       "      <td>0.842079</td>\n",
       "      <td>0.905218</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>0.026754</td>\n",
       "      <td>0.066931</td>\n",
       "      <td>0.114192</td>\n",
       "      <td>0.204323</td>\n",
       "      <td>0.338185</td>\n",
       "      <td>0.605930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight=None, ...</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>0.653625</td>\n",
       "      <td>0.746965</td>\n",
       "      <td>0.978003</td>\n",
       "      <td>0.962775</td>\n",
       "      <td>0.943862</td>\n",
       "      <td>0.922895</td>\n",
       "      <td>0.892721</td>\n",
       "      <td>0.870428</td>\n",
       "      <td>0.830724</td>\n",
       "      <td>0.013083</td>\n",
       "      <td>0.025758</td>\n",
       "      <td>0.063173</td>\n",
       "      <td>0.123540</td>\n",
       "      <td>0.239022</td>\n",
       "      <td>0.349570</td>\n",
       "      <td>0.556066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.605342</td>\n",
       "      <td>0.746965</td>\n",
       "      <td>0.878173</td>\n",
       "      <td>0.868020</td>\n",
       "      <td>0.876902</td>\n",
       "      <td>0.863037</td>\n",
       "      <td>0.837433</td>\n",
       "      <td>0.824438</td>\n",
       "      <td>0.807290</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.023223</td>\n",
       "      <td>0.058692</td>\n",
       "      <td>0.115527</td>\n",
       "      <td>0.224219</td>\n",
       "      <td>0.331100</td>\n",
       "      <td>0.540380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type                                                clf  \\\n",
       "0         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "1         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "2        KNN  KNeighborsClassifier(algorithm='auto', leaf_si...   \n",
       "3         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "4         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "5         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "6         LR  LogisticRegression(C=0.01, class_weight=None, ...   \n",
       "7         NB                            GaussianNB(priors=None)   \n",
       "\n",
       "                                          parameters   auc-roc  baseline  \\\n",
       "0  {'max_depth': 1, 'max_features': 'sqrt', 'min_...  0.501993  0.746965   \n",
       "1  {'criterion': 'gini', 'max_depth': 1, 'min_sam...  0.602844  0.746965   \n",
       "2  {'algorithm': 'auto', 'n_neighbors': 5, 'weigh...  0.580896  0.746965   \n",
       "3  {'criterion': 'gini', 'max_depth': 1, 'max_fea...  0.508140  0.746965   \n",
       "4          {'algorithm': 'SAMME', 'n_estimators': 1}  0.602844  0.746965   \n",
       "5  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti...  0.602959  0.746965   \n",
       "6                       {'C': 0.01, 'penalty': 'l1'}  0.653625  0.746965   \n",
       "7                                                 {}  0.605342  0.746965   \n",
       "\n",
       "     p_at_1    p_at_2    p_at_5   p_at_10   p_at_20   p_at_30   p_at_50  \\\n",
       "0  0.925550  0.962775  0.985120  0.992560  0.996280  0.997520  0.998478   \n",
       "1  1.000000  1.000000  1.000000  0.852215  0.763294  0.842191  0.905285   \n",
       "2  1.000000  1.000000  1.000000  0.669598  0.816806  0.823311  0.843404   \n",
       "3  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "4  1.000000  1.000000  1.000000  0.852215  0.763294  0.842191  0.905285   \n",
       "5  1.000000  1.000000  1.000000  0.853061  0.763125  0.842079  0.905218   \n",
       "6  0.978003  0.962775  0.943862  0.922895  0.892721  0.870428  0.830724   \n",
       "7  0.878173  0.868020  0.876902  0.863037  0.837433  0.824438  0.807290   \n",
       "\n",
       "     r_at_1    r_at_2    r_at_5   r_at_10   r_at_20   r_at_30   r_at_50  \n",
       "0  0.012381  0.025758  0.065935  0.132866  0.266750  0.400611  0.668357  \n",
       "1  0.013377  0.026754  0.066931  0.114079  0.204368  0.338230  0.605976  \n",
       "2  0.013377  0.026754  0.066931  0.089633  0.218696  0.330647  0.564554  \n",
       "3  0.013377  0.026754  0.066931  0.133861  0.267746  0.401607  0.669375  \n",
       "4  0.013377  0.026754  0.066931  0.114079  0.204368  0.338230  0.605976  \n",
       "5  0.013377  0.026754  0.066931  0.114192  0.204323  0.338185  0.605930  \n",
       "6  0.013083  0.025758  0.063173  0.123540  0.239022  0.349570  0.556066  \n",
       "7  0.011747  0.023223  0.058692  0.115527  0.224219  0.331100  0.540380  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_loop(classify, features, 'Jul 2011')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "DT\n",
      "KNN\n",
      "ET\n",
      "AB\n",
      "GB\n",
      "LR\n",
      "NB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>clf</th>\n",
       "      <th>parameters</th>\n",
       "      <th>auc-roc</th>\n",
       "      <th>baseline</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>r_at_2</th>\n",
       "      <th>r_at_5</th>\n",
       "      <th>r_at_10</th>\n",
       "      <th>r_at_20</th>\n",
       "      <th>r_at_30</th>\n",
       "      <th>r_at_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 1, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.503013</td>\n",
       "      <td>0.684614</td>\n",
       "      <td>0.849885</td>\n",
       "      <td>0.450346</td>\n",
       "      <td>0.780240</td>\n",
       "      <td>0.890145</td>\n",
       "      <td>0.945073</td>\n",
       "      <td>0.963382</td>\n",
       "      <td>0.978029</td>\n",
       "      <td>0.012405</td>\n",
       "      <td>0.013147</td>\n",
       "      <td>0.056969</td>\n",
       "      <td>0.130019</td>\n",
       "      <td>0.276083</td>\n",
       "      <td>0.422147</td>\n",
       "      <td>0.714276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.609310</td>\n",
       "      <td>0.684614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901685</td>\n",
       "      <td>0.667667</td>\n",
       "      <td>0.778444</td>\n",
       "      <td>0.867067</td>\n",
       "      <td>0.014596</td>\n",
       "      <td>0.029193</td>\n",
       "      <td>0.073015</td>\n",
       "      <td>0.131704</td>\n",
       "      <td>0.195045</td>\n",
       "      <td>0.341109</td>\n",
       "      <td>0.633238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 5, 'weigh...</td>\n",
       "      <td>0.587878</td>\n",
       "      <td>0.684614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625894</td>\n",
       "      <td>0.737711</td>\n",
       "      <td>0.825140</td>\n",
       "      <td>0.833695</td>\n",
       "      <td>0.014596</td>\n",
       "      <td>0.029193</td>\n",
       "      <td>0.073015</td>\n",
       "      <td>0.091421</td>\n",
       "      <td>0.215506</td>\n",
       "      <td>0.361571</td>\n",
       "      <td>0.608866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ET</td>\n",
       "      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'max_fea...</td>\n",
       "      <td>0.550736</td>\n",
       "      <td>0.684614</td>\n",
       "      <td>0.997691</td>\n",
       "      <td>0.998845</td>\n",
       "      <td>0.999538</td>\n",
       "      <td>0.999769</td>\n",
       "      <td>0.838334</td>\n",
       "      <td>0.892146</td>\n",
       "      <td>0.935241</td>\n",
       "      <td>0.014563</td>\n",
       "      <td>0.029159</td>\n",
       "      <td>0.072982</td>\n",
       "      <td>0.146031</td>\n",
       "      <td>0.244901</td>\n",
       "      <td>0.390932</td>\n",
       "      <td>0.683027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'algorithm': 'SAMME', 'n_estimators': 1}</td>\n",
       "      <td>0.609310</td>\n",
       "      <td>0.684614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901685</td>\n",
       "      <td>0.667667</td>\n",
       "      <td>0.778444</td>\n",
       "      <td>0.867067</td>\n",
       "      <td>0.014596</td>\n",
       "      <td>0.029193</td>\n",
       "      <td>0.073015</td>\n",
       "      <td>0.131704</td>\n",
       "      <td>0.195045</td>\n",
       "      <td>0.341109</td>\n",
       "      <td>0.633238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>0.609491</td>\n",
       "      <td>0.684614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904454</td>\n",
       "      <td>0.666167</td>\n",
       "      <td>0.777444</td>\n",
       "      <td>0.866467</td>\n",
       "      <td>0.014596</td>\n",
       "      <td>0.029193</td>\n",
       "      <td>0.073015</td>\n",
       "      <td>0.132109</td>\n",
       "      <td>0.194606</td>\n",
       "      <td>0.340671</td>\n",
       "      <td>0.632800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=0.01, class_weight=None, ...</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>0.632213</td>\n",
       "      <td>0.684614</td>\n",
       "      <td>0.856813</td>\n",
       "      <td>0.808314</td>\n",
       "      <td>0.821791</td>\n",
       "      <td>0.830602</td>\n",
       "      <td>0.827371</td>\n",
       "      <td>0.808524</td>\n",
       "      <td>0.767459</td>\n",
       "      <td>0.012506</td>\n",
       "      <td>0.023597</td>\n",
       "      <td>0.060003</td>\n",
       "      <td>0.121321</td>\n",
       "      <td>0.241699</td>\n",
       "      <td>0.354290</td>\n",
       "      <td>0.560492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB</td>\n",
       "      <td>GaussianNB(priors=None)</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.587471</td>\n",
       "      <td>0.684614</td>\n",
       "      <td>0.801386</td>\n",
       "      <td>0.804850</td>\n",
       "      <td>0.780240</td>\n",
       "      <td>0.775213</td>\n",
       "      <td>0.769675</td>\n",
       "      <td>0.769367</td>\n",
       "      <td>0.742165</td>\n",
       "      <td>0.011697</td>\n",
       "      <td>0.023496</td>\n",
       "      <td>0.056969</td>\n",
       "      <td>0.113231</td>\n",
       "      <td>0.224844</td>\n",
       "      <td>0.337131</td>\n",
       "      <td>0.542019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type                                                clf  \\\n",
       "0         RF  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "1         DT  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "2        KNN  KNeighborsClassifier(algorithm='auto', leaf_si...   \n",
       "3         ET  (ExtraTreeClassifier(class_weight=None, criter...   \n",
       "4         AB  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "5         GB  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "6         LR  LogisticRegression(C=0.01, class_weight=None, ...   \n",
       "7         NB                            GaussianNB(priors=None)   \n",
       "\n",
       "                                          parameters   auc-roc  baseline  \\\n",
       "0  {'max_depth': 1, 'max_features': 'sqrt', 'min_...  0.503013  0.684614   \n",
       "1  {'criterion': 'gini', 'max_depth': 1, 'min_sam...  0.609310  0.684614   \n",
       "2  {'algorithm': 'auto', 'n_neighbors': 5, 'weigh...  0.587878  0.684614   \n",
       "3  {'criterion': 'gini', 'max_depth': 1, 'max_fea...  0.550736  0.684614   \n",
       "4          {'algorithm': 'SAMME', 'n_estimators': 1}  0.609310  0.684614   \n",
       "5  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti...  0.609491  0.684614   \n",
       "6                       {'C': 0.01, 'penalty': 'l1'}  0.632213  0.684614   \n",
       "7                                                 {}  0.587471  0.684614   \n",
       "\n",
       "     p_at_1    p_at_2    p_at_5   p_at_10   p_at_20   p_at_30   p_at_50  \\\n",
       "0  0.849885  0.450346  0.780240  0.890145  0.945073  0.963382  0.978029   \n",
       "1  1.000000  1.000000  1.000000  0.901685  0.667667  0.778444  0.867067   \n",
       "2  1.000000  1.000000  1.000000  0.625894  0.737711  0.825140  0.833695   \n",
       "3  0.997691  0.998845  0.999538  0.999769  0.838334  0.892146  0.935241   \n",
       "4  1.000000  1.000000  1.000000  0.901685  0.667667  0.778444  0.867067   \n",
       "5  1.000000  1.000000  1.000000  0.904454  0.666167  0.777444  0.866467   \n",
       "6  0.856813  0.808314  0.821791  0.830602  0.827371  0.808524  0.767459   \n",
       "7  0.801386  0.804850  0.780240  0.775213  0.769675  0.769367  0.742165   \n",
       "\n",
       "     r_at_1    r_at_2    r_at_5   r_at_10   r_at_20   r_at_30   r_at_50  \n",
       "0  0.012405  0.013147  0.056969  0.130019  0.276083  0.422147  0.714276  \n",
       "1  0.014596  0.029193  0.073015  0.131704  0.195045  0.341109  0.633238  \n",
       "2  0.014596  0.029193  0.073015  0.091421  0.215506  0.361571  0.608866  \n",
       "3  0.014563  0.029159  0.072982  0.146031  0.244901  0.390932  0.683027  \n",
       "4  0.014596  0.029193  0.073015  0.131704  0.195045  0.341109  0.633238  \n",
       "5  0.014596  0.029193  0.073015  0.132109  0.194606  0.340671  0.632800  \n",
       "6  0.012506  0.023597  0.060003  0.121321  0.241699  0.354290  0.560492  \n",
       "7  0.011697  0.023496  0.056969  0.113231  0.224844  0.337131  0.542019  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_loop(classify, features, 'Jan 2012')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def main(df, features=features, outcome='6M', \n",
    "         models='all', grid_size='test', prediction_time='date_posted', \n",
    "         outcomes=['6M'], validate_end_dates=['2013-05-31']):\n",
    "    \n",
    "    validation_dates = []\n",
    "    for date in validate_end_dates:\n",
    "        temp = datetime.strptime(date, '%Y-%m-%d')\n",
    "\n",
    "\n",
    "    # models_to_run=['RF','DT','KNN', 'ET', 'AB', 'GB', 'LR', 'NB']\n",
    "    if (models == 'all'):\n",
    "        models_to_run=['RF','LR','DT','ET','AB']\n",
    "    else:\n",
    "        models_to_run = []\n",
    "        models_to_run.append(model)\n",
    "\n",
    "    clfs, grid = define_clfs_params(grid_size)\n",
    "    print(\"defined clfs params\")                                                                                                      \n",
    "\n",
    "    all_predictors=features\n",
    "\n",
    "    # define dataframe to write results to\n",
    "    results_df =  pd.DataFrame(columns=('model_type','clf', 'parameters', 'outcome', 'validation_date', 'group',\n",
    "                                        'train_set_size', 'validation_set_size','predictors',\n",
    "                                        'baseline','precision_at_5','precision_at_10','precision_at_20','precision_at_30','precision_at_40',\n",
    "                                        'precision_at_50','recall_at_5','recall_at_10','recall_at_20','recall_at_30','recall_at_40',\n",
    "                                        'recall_at_50','auc-roc'))\n",
    "\n",
    "    \n",
    "    print(\"made results df\")\n",
    "    # the magic loop starts here\n",
    "    # we will loop over models, parameters, outcomes, validation_Dates\n",
    "    # and store several evaluation metrics\n",
    "\n",
    "    for index,clf in enumerate([clfs[x] for x in models_to_run]):\n",
    "        parameter_values = grid[models_to_run[index]]\n",
    "        for p in ParameterGrid(parameter_values):\n",
    "            for current_outcome in outcomes:\n",
    "                for predictor in all_predictors:\n",
    "                    for validation_date in validation_dates:\n",
    "                        print(p, current_outcome, predictor, validation_date)\n",
    "                                                                                                           \n",
    "                        try:\n",
    "                            print(models_to_run[index])\n",
    "                            clf.set_params(**p)\n",
    "                            if (outcome == '6M'):\n",
    "                                delta = 180\n",
    "                            else:\n",
    "                                raise ValueError('value of outcome is unknown')                 \n",
    "                        \n",
    "                            train_set = df[df[prediction_time] <= datetime.strptime(validation_date, '%Y-%m-%d') - timedelta(days=delta)]\n",
    "                            # fill in missing values for train set using just the train set\n",
    "                            # we'll do it a very naive way here but you should think more carefully about this first\n",
    "                            train_set.fillna(train_set.mean(), inplace=True)\n",
    "                            train_set.dropna(axis=1, how='any', inplace=True)\n",
    "                            \n",
    "                            validation_set = df[df[prediction_time] > datetime.strptime(validation_date, '%Y-%m-%d') - timedelta(days=0)]\n",
    "                            # fill in missing values for validation set using all the data\n",
    "                            # we'll do it a very naive way here but you should think more carefully about this first\n",
    "                            validation_set.fillna(df.mean(), inplace=True)\n",
    "                            validation_set.dropna(axis=1, how='any', inplace=True)\n",
    "\n",
    "                            print(predictor)\n",
    "                            # get predictors by removing those dropped by dropna\n",
    "                            predictors_to_use = list(set(predictor).intersection(train_set.columns))\n",
    "\n",
    "                            model = clf.fit(train_set[predictor], train_set[current_outcome]) \n",
    "                            pred_probs = clf.predict_proba(validation_set[predictor])[::,1]\n",
    "                            print(len(train_set))\n",
    "                            print(len(validation_set))\n",
    "                            #pred_probs_sorted, true_outcome_sorted = zip(*sorted(zip(pred_probs, validation_set[current_outcome]), reverse=True))\n",
    "                            results_df.loc[len(results_df)] = [models_to_run[index],clf, p, current_outcome, validation_date, group,\n",
    "                                                               len(train_set),len(validation_set), \n",
    "                                                               predictor, \n",
    "                                                                precision_at_k(validation_set[current_outcome],pred_probs, 100),\n",
    "                                                                precision_at_k(validation_set[current_outcome],pred_probs, 5),\n",
    "                                                                precision_at_k(validation_set[current_outcome],pred_probs, 10),\n",
    "                                                                precision_at_k(validation_set[current_outcome],pred_probs, 20),\n",
    "                                                                precision_at_k(validation_set[current_outcome],pred_probs, 30),\n",
    "                                                                precision_at_k(validation_set[current_outcome],pred_probs, 40),\n",
    "                                                                precision_at_k(validation_set[current_outcome],pred_probs, 50),\n",
    "                                                                recall_at_k(validation_set[current_outcome],pred_probs, 5),\n",
    "                                                                recall_at_k(validation_set[current_outcome],pred_probs, 10),\n",
    "                                                                recall_at_k(validation_set[current_outcome],pred_probs, 20),\n",
    "                                                                recall_at_k(validation_set[current_outcome],pred_probs, 30),\n",
    "                                                                recall_at_k(validation_set[current_outcome],pred_probs, 40),\n",
    "                                                                recall_at_k(validation_set[current_outcome],pred_probs, 50),\n",
    "                                                                roc_auc_score(validation_set[current_outcome], pred_probs)]\n",
    "\n",
    "                            # plot precision recall graph\n",
    "                            # we'll show them here but you can also save them to disk\n",
    "                            plot_precision_recall_n(validation_set[current_outcome], pred_probs, clf, 'show')\n",
    "                            # write results to csv as they come in so we always have something to see even if models runs for days\n",
    "                           \n",
    "                        except IndexError:\n",
    "                            continue\n",
    "    \n",
    "\n",
    "    return results_df\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(classify, features=features, outcome='6M', models='all', grid_size='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample config file to run temporal validation\n",
    "\n",
    "# start time of our data\n",
    "start_time = '2011-01-01'\n",
    "\n",
    "#last date of data including labels and outcomes that we have\n",
    "end_time = '2013-12-31'\n",
    "\n",
    "#how far out do we want to predict (let's say in months for now)\n",
    "prediction_windows = [6, 12]\n",
    "prediction_window = 6\n",
    "\n",
    "#how often is this prediction being made? every day? every month? once a year?\n",
    "update_window = 12\n",
    "\n",
    "from datetime import date, datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "start_dt = datetime.strptime(start_time, '%Y-%m-%d')\n",
    "end_dt = datetime.strptime(end_time, '%Y-%m-%d')\n",
    "\n",
    "dates_dict = {}\n",
    "last_end_test= start_dt + relativedelta(months=+prediction_window) + relativedelta(months=+update_window)\n",
    "print(last_end_test)\n",
    "end_test = end_dt - relativedelta(months=+prediction_window)\n",
    "\n",
    "start = (last_end_test  - relativedelta(months=+update_window)) + relativedelta(days=+2)\n",
    "#print(\"start\", start)\n",
    "end_train = end_test - relativedelta(months=+prediction_window)\n",
    "#print(\"end_train\", end_train)\n",
    "end_test = end_dt - relativedelta(months=+prediction_window)\n",
    "#print(\"end_test\",end_test)\n",
    "\n",
    "dates_dict[start] = [end_train, end_test]\n",
    "print(dates_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
